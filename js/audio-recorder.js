// Audio Recording Module
// Handles microphone access, recording, and audio processing

class AudioRecorder {
  constructor() {
    this.mediaRecorder = null;
    this.audioChunks = [];
    this.isRecording = false;
    this.stream = null;
  }

  async requestMicrophoneAccess() {
    console.log('ðŸŽ¤ Requesting microphone access...');
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('âœ… Microphone access granted');
      console.log('ðŸ“¡ Stream details:', {
        active: this.stream.active,
        audioTracks: this.stream.getAudioTracks().length,
        videoTracks: this.stream.getVideoTracks().length
      });
      return this.stream;
    } catch (error) {
      console.error('âŒ === MICROPHONE ACCESS ERROR ===');
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      console.error('âŒ === END MICROPHONE ACCESS ERROR ===');
      throw error;
    }
  }

  startRecording(stream) {
    console.log('ðŸŽ¬ Starting recording session...');
    console.log('ðŸ“¡ Stream details:', {
      active: stream.active,
      audioTracks: stream.getAudioTracks().length,
      videoTracks: stream.getVideoTracks().length
    });
    
    this.audioChunks = [];
    this.mediaRecorder = new MediaRecorder(stream, {
      mimeType: 'audio/webm;codecs=opus'
    });
    
    console.log('ðŸ“¹ MediaRecorder created:', {
      mimeType: this.mediaRecorder.mimeType,
      state: this.mediaRecorder.state
    });

    this.mediaRecorder.ondataavailable = (event) => {
      console.log('ðŸ“Š Audio chunk received:', {
        size: event.data.size,
        type: event.data.type
      });
      if (event.data.size > 0) {
        this.audioChunks.push(event.data);
      }
    };

    return new Promise((resolve) => {
      this.mediaRecorder.onstop = () => {
        console.log('â¹ï¸ Recording stopped, processing audio...');
        console.log('ðŸ“Š Total chunks collected:', this.audioChunks.length);
        
        const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
        console.log('ðŸŽµ Audio blob created:', {
          size: audioBlob.size,
          type: audioBlob.type
        });
        
        this.stopMediaTracks();
        resolve(audioBlob);
      };

      console.log('â–¶ï¸ Starting MediaRecorder...');
      this.mediaRecorder.start();
      this.isRecording = true;
      console.log('âœ… Recording started successfully');
    });
  }

  stopRecording() {
    console.log('â¹ï¸ Stopping current recording...');
    if (this.mediaRecorder && this.isRecording) {
      this.mediaRecorder.stop();
      this.isRecording = false;
      console.log('âœ… Recording stop signal sent');
    }
  }

  stopMediaTracks() {
    if (this.stream) {
      console.log('ðŸŽ¤ Stopping media tracks...');
      this.stream.getTracks().forEach(track => {
        console.log('ðŸ”‡ Stopping track:', track.kind, track.label);
        track.stop();
      });
      console.log('âœ… All tracks stopped');
      this.stream = null;
    }
  }

  getRecordingState() {
    return {
      isRecording: this.isRecording,
      hasStream: !!this.stream,
      recorderState: this.mediaRecorder?.state
    };
  }
}

// Export for use in other modules
window.AudioRecorder = AudioRecorder;